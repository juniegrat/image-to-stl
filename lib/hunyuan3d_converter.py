#!/usr/bin/env python3
"""
Module de conversion STL pour Hunyuan3D-2mv
G√®re la conversion d'images de pi√®ces (avers/revers) en mod√®les STL 3D haute fid√©lit√©
Utilise des utilitaires modulaires pour l'ind√©pendance compl√®te
"""

import os
import sys
import time
import warnings
from pathlib import Path
from typing import List, Optional

import torch
import numpy as np
from PIL import Image
import trimesh
import rembg
from tqdm import tqdm

# Import des utilitaires Hunyuan3D
try:
    # Import relatif quand utilis√© comme module
    from .hunyuan3d_utils import (
        get_ray_directions,
        get_rays,
        get_spherical_cameras,
        save_video,
        to_gradio_3d_orientation,
        remove_background,
        resize_foreground,
        normalize_mesh,
        render_mesh_view,
        debug_mesh_properties,
        get_hunyuan3d_info,
        use_generated_video_if_available,
        copy_generated_renders
    )
except ImportError:
    # Import absolu quand utilis√© directement
    from hunyuan3d_utils import (
        get_ray_directions,
        get_rays,
        get_spherical_cameras,
        save_video,
        to_gradio_3d_orientation,
        remove_background,
        resize_foreground,
        normalize_mesh,
        render_mesh_view,
        debug_mesh_properties,
        get_hunyuan3d_info,
        use_generated_video_if_available,
        copy_generated_renders
    )

# Supprimer les warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)


class Hunyuan3DConverter:
    """
    Convertisseur principal pour Hunyuan3D-2mv
    Optimis√© pour les pi√®ces numismatiques avec support multi-view
    Rendu vid√©o avec utilitaires modulaires ind√©pendants
    """

    def __init__(self, model_path="tencent/Hunyuan3D-2",
                 texture_model_path="tencent/Hunyuan3D-2",
                 device=None,
                 disable_texture=False):
        """
        Initialise le convertisseur Hunyuan3D-2mv

        Args:
            model_path: Chemin vers le mod√®le de forme (d√©faut: Hunyuan3D-2mv)
            texture_model_path: Chemin vers le mod√®le de texture
            device: Device √† utiliser (auto-d√©tect√© si None)
            disable_texture: D√©sactiver compl√®tement le chargement du mod√®le de texture
        """
        self.model_path = model_path
        self.texture_model_path = texture_model_path
        self.device = device or (
            "cuda" if torch.cuda.is_available() else "cpu")
        self.disable_texture = disable_texture

        # Pipelines (charg√©s √† la demande)
        self.shape_pipeline = None
        self.texture_pipeline = None

        # Configuration par d√©faut (niveau "high" - optimis√© pour pi√®ces)
        self.config = {
            'image_size': 1024,  # R√©solution √©lev√©e pour capturer les d√©tails fins
            'guidance_scale': 15.0,  # √âlev√© pour une meilleure forme
            'num_inference_steps': 100,  # Plus d'√©tapes pour plus de pr√©cision
            'octree_resolution': 380,  # R√©solution mesh √©lev√©e pour d√©tails
            'num_chunks': 20000,  # Complexit√© √©lev√©e
            'texture_guidance_scale': 6.0,  # √âlev√© pour les d√©tails de texture
            'texture_steps': 60,  # Plus d'√©tapes pour les d√©tails fins
            'seed': 12345,
            # Param√®tres de rendu optimis√©s
            'n_views': 36,  # Diviseur de 360¬∞ pour rotation parfaite
            'elevation_deg': 15.0,  # Angle optimal pour capturer la profondeur
            'camera_distance': 1.5,  # Plus proche pour capturer les d√©tails
            'fovy_deg': 30.0,  # Angle de vue serr√© pour r√©duire la distortion
            'height': 1024,  # R√©solution √©lev√©e pour les d√©tails
            'width': 1024,   # R√©solution √©lev√©e pour les d√©tails
            'fps': 30,
            'foreground_ratio': 0.95  # Ratio √©lev√© pour capturer tout l'objet
        }

        # Session rembg pour la suppression d'arri√®re-plan
        self.rembg_session = None

        print(f"üîß Convertisseur Hunyuan3D-2mv initialis√© (utilitaires modulaires)")
        print(f"   Device: {self.device}")
        print(f"   Mod√®le forme: {self.model_path}")
        print(f"   Mod√®le texture: {self.texture_model_path}")

    def enable_test_mode(self):
        """Active le mode test ultra-rapide pour les tests et d√©veloppement"""
        print("‚ö° Activation du mode TEST ultra-rapide")
        print("   üöÄ R√©solution: 256x256 (vitesse maximale)")
        print("   üöÄ Guidance scale: 2.0 (tr√®s minimal)")
        print("   üöÄ Steps: 10 (ultra-rapide)")
        print("   üöÄ Octree resolution: 64 (mesh tr√®s simple)")
        print("   üöÄ Chunks: 1000 (complexit√© minimale)")
        print("   üöÄ Texture steps: 8 (minimal)")
        print("   üöÄ Rendus: 8 vues (au lieu de 36)")
        print("   ‚ö° OPTIMIS√â POUR TESTS - PAS POUR PRODUCTION")

        # Configuration test ultra-rapide et agressive
        self.config = {
            # Param√®tres de g√©n√©ration (ultra-rapides)
            'image_size': 256,  # Tr√®s petite r√©solution pour vitesse
            'guidance_scale': 2.0,  # Plus bas que 3.0
            'num_inference_steps': 10,  # Tr√®s peu d'√©tapes
            'octree_resolution': 64,  # NOUVEAU: R√©solution mesh tr√®s basse
            'num_chunks': 1000,  # NOUVEAU: Complexit√© minimale
            'texture_guidance_scale': 1.5,  # Minimal pour texture
            'texture_steps': 8,  # Tr√®s peu d'√©tapes texture
            'seed': 42,
            # Param√®tres de rendu (simplifi√©s)
            'n_views': 8,  # Seulement 8 vues au lieu de 36
            'elevation_deg': 0.0,  # Angle simple
            'camera_distance': 2.5,  # Distance normale
            'fovy_deg': 45.0,  # Angle standard
            'height': 256,  # Petite r√©solution rendu
            'width': 256,   # Petite r√©solution rendu
            'fps': 12,  # Moins de FPS
            'foreground_ratio': 0.8,
            # Mode test agressif
            'test_mode': True,
            'quick_render': True,
            'skip_post_processing': True,  # √âviter les traitements longs
            'low_precision': True,  # Utiliser une pr√©cision r√©duite
        }

        # Initialiser rembg rapidement si pas d√©j√† fait
        if not self.rembg_session:
            try:
                import rembg
                self.rembg_session = rembg.new_session(
                    'u2net')  # Plus rapide que le d√©faut
                print("   ‚úÖ Session rembg rapide initialis√©e")
            except ImportError:
                print("   ‚ö†Ô∏è  rembg non disponible, suppression arri√®re-plan d√©sactiv√©e")

    def enable_debug_mode(self):
        """Active le mode debug ultra-minimal pour tests instantan√©s"""
        print("‚ö° Activation du mode DEBUG (mod√®le lisse et simple)")
        print("   üöÄ R√©solution: 256x256 (minimal mais coh√©rent)")
        print("   üöÄ Guidance scale: 3.0 (minimal mais forme reconnaissable)")
        print("   üöÄ Steps: 15 (rapide mais √©vite les artefacts)")
        print("   üöÄ Octree resolution: 96 (mesh simple mais lisse)")
        print("   üöÄ Chunks: 1500 (complexit√© simple)")
        print("   üöÄ Texture steps: 8 (minimal)")
        print("   üöÄ Rendus: 8 vues seulement")
        print("   üöÄ Mode flat: mesh lisse avec minimum de vertices")
        print("   ‚ö° OPTIMIS√â POUR TESTS RAPIDES AVEC MOD√àLE COH√âRENT")

        # Configuration debug √©quilibr√©e : rapide mais pas d'artefacts
        self.config = {
            # Param√®tres de g√©n√©ration (rapides mais coh√©rents)
            'image_size': 256,  # Petite r√©solution mais pas trop
            'guidance_scale': 3.0,  # Assez pour une forme reconnaissable
            'num_inference_steps': 15,  # Suffisant pour √©viter les artefacts
            'octree_resolution': 96,  # R√©solution mesh simple mais lisse
            'num_chunks': 1500,  # Complexit√© simple mais suffisante
            'texture_guidance_scale': 2.0,  # Minimal mais fonctionnel
            'texture_steps': 8,  # Peu d'√©tapes texture
            'seed': 42,
            # Param√®tres de rendu (simplifi√©s mais corrects)
            'n_views': 8,  # 8 vues suffisantes pour debug
            'elevation_deg': 5.0,  # L√©ger angle pour voir la forme
            'camera_distance': 2.0,  # Distance raisonnable
            'fovy_deg': 40.0,  # Angle standard
            'height': 256,  # Petite r√©solution rendu
            'width': 256,   # Petite r√©solution rendu
            'fps': 12,  # FPS r√©duit
            'foreground_ratio': 0.8,
            # Mode debug √©quilibr√©
            'debug_mode': True,
            'quick_render': True,
            'skip_post_processing': True,  # √âviter les traitements longs
            'simple_mesh': True,  # Mesh simple mais lisse
            'preserve_shape': True,  # Pr√©server la forme de base
            'minimal_vertices': True,  # Nombre minimal de vertices
        }

        # Pas besoin de rembg en mode debug
        print("   üöÄ Suppression arri√®re-plan d√©sactiv√©e en mode debug")

    def enable_fast_mode(self):
        """Active le mode rapide (compromis qualit√©/vitesse)"""
        print("üèÉ Activation du mode RAPIDE (compromis qualit√©/vitesse)")
        print("   ‚ö° R√©solution: 512x512 (qualit√© correcte)")
        print("   ‚ö° Guidance scale: 7.0 (√©quilibr√©)")
        print("   ‚ö° Steps: 50 (raisonnable)")
        print("   ‚ö° Texture steps: 25 (√©quilibr√©)")
        print("   ‚ö° Rendus: 24 vues")

        # Configuration rapide mais qualit√© correcte
        self.config = {
            'image_size': 512,  # R√©solution interm√©diaire
            'guidance_scale': 7.0,  # √âquilibr√©
            'num_inference_steps': 50,  # Moiti√© du mode pi√®ce
            'octree_resolution': 192,  # R√©solution mesh r√©duite
            'num_chunks': 5000,  # Complexit√© r√©duite
            'texture_guidance_scale': 3.0,  # √âquilibr√©
            'texture_steps': 25,  # Moiti√© du mode pi√®ce
            'seed': 42,
            # Param√®tres de rendu √©quilibr√©s
            'n_views': 24,  # 24 vues suffisantes
            'elevation_deg': 12.0,
            'camera_distance': 1.6,
            'fovy_deg': 35.0,
            'height': 512,
            'width': 512,
            'fps': 24,
            'foreground_ratio': 0.90,
            # Optimisations
            'fast_mode': True,
            'moderate_post_processing': True
        }

    def enable_ultra_mode(self):
        """Active le mode ultra qualit√© (param√®tres maximaux)"""
        print("üåü Activation du mode ULTRA qualit√©")
        print("   üéØ R√©solution: 1024x1024 (haute d√©finition)")
        print("   üéØ Guidance scale: 20.0 (pr√©cision maximale)")
        print("   üéØ Steps: 150 (qualit√© ultime)")
        print("   üéØ Texture steps: 80 (d√©tails fins)")
        print("   üéØ Rendus: 48 vues (rendu premium)")
        print("   üåü QUALIT√â MAXIMALE - TEMPS DE RENDU √âLEV√â")

        # Configuration ultra qualit√©
        self.config = {
            'image_size': 1024,  # Haute r√©solution
            'guidance_scale': 20.0,  # Tr√®s √©lev√© pour pr√©cision maximale
            'num_inference_steps': 150,  # Beaucoup d'√©tapes
            'octree_resolution': 512,  # R√©solution mesh tr√®s √©lev√©e
            'num_chunks': 30000,  # Complexit√© maximale
            'texture_guidance_scale': 8.0,  # Tr√®s √©lev√© pour texture
            'texture_steps': 80,  # Beaucoup d'√©tapes texture
            'seed': 12345,
            # Param√®tres de rendu premium
            'n_views': 48,  # Plus de vues pour plus de d√©tails
            'elevation_deg': 20.0,  # Angle optimal
            'camera_distance': 1.4,  # Tr√®s proche pour d√©tails
            'fovy_deg': 25.0,  # Angle serr√©
            'height': 1024,
            'width': 1024,
            'fps': 30,
            'foreground_ratio': 0.98,  # Ratio maximum
            # Optimisations qualit√©
            'ultra_mode': True,
            'max_post_processing': True,
            'anti_aliasing': True,
            'detail_preservation': True
        }

        # Initialiser rembg avec le meilleur mod√®le
        if not self.rembg_session:
            try:
                import rembg
                self.rembg_session = rembg.new_session(
                    'u2net')  # Meilleur mod√®le
                print("   ‚úÖ Session rembg premium initialis√©e")
            except ImportError:
                print("   ‚ö†Ô∏è  rembg non disponible, suppression arri√®re-plan d√©sactiv√©e")

    def check_environment(self):
        """V√©rifie l'environnement et les d√©pendances"""
        print("üîç V√©rification de l'environnement...")

        # V√©rifier CUDA
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA: {torch.cuda.get_device_name(0)}")
            print(
                f"   M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("‚ö†Ô∏è  CUDA non disponible")

        # V√©rifier les d√©pendances critiques
        deps = ['diffusers', 'transformers', 'accelerate', 'torch',
                'torchvision', 'PIL', 'numpy', 'trimesh', 'imageio', 'rembg', 'tqdm', 'matplotlib']
        missing = []

        for dep in deps:
            try:
                if dep == 'PIL':
                    import PIL
                elif dep == 'matplotlib':
                    import matplotlib.pyplot as plt
                else:
                    __import__(dep)
            except ImportError:
                missing.append(dep)

        if missing:
            print(f"‚ùå D√©pendances manquantes: {', '.join(missing)}")
            return False

        print("‚úÖ Toutes les d√©pendances sont disponibles")
        return True

    def load_models(self):
        """Charge les mod√®les Hunyuan3D-2"""
        print("ü§ñ Chargement des mod√®les...")

        try:
            # Importer les classes n√©cessaires
            from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline
            from hy3dgen.texgen import Hunyuan3DPaintPipeline

            # Charger le mod√®le de forme
            print(f"   üìê Chargement du mod√®le de forme...")
            try:
                self.shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
                    self.model_path,
                    torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    device_map="auto" if self.device == "cuda" else None,
                    trust_remote_code=True,
                    cache_dir=None  # Utilise le cache HF standard
                )
                print(f"   ‚úÖ Mod√®le de forme charg√© avec succ√®s!")
            except Exception as e:
                print(f"   ‚ùå Erreur chargement mod√®le de forme: {e}")
                return False

            # Charger le mod√®le de texture avec gestion d'erreurs am√©lior√©e
            if self.disable_texture:
                print("   üö´ Chargement du mod√®le de texture d√©sactiv√©")
                print("   üìã Mode disponible: g√©n√©ration de forme uniquement")
                self.texture_pipeline = None
            else:
                print("   üé® Chargement du mod√®le de texture...")
                try:
                    # Essayer plusieurs chemins possibles pour le mod√®le de texture
                    texture_paths = [
                        self.texture_model_path,
                        "tencent/Hunyuan3D-2",  # Utilise le cache HF standard
                    ]

                    texture_loaded = False
                    for path in texture_paths:
                        try:
                            print(f"      Tentative avec: {path}")
                            # Hunyuan3DPaintPipeline ne supporte que l'argument path dans from_pretrained()
                            self.texture_pipeline = Hunyuan3DPaintPipeline.from_pretrained(
                                path
                            )

                            # D√©placer vers le device manuellement si n√©cessaire
                            if hasattr(self.texture_pipeline, 'to'):
                                self.texture_pipeline = self.texture_pipeline.to(
                                    self.device)

                            print("   ‚úÖ Mod√®le de texture charg√© avec succ√®s!")
                            texture_loaded = True
                            break
                        except Exception as e:
                            print(f"      ‚ö†Ô∏è  √âchec avec {path}: {e}")
                            continue

                    if not texture_loaded:
                        print("   ‚ö†Ô∏è  Impossible de charger le mod√®le de texture")
                        print("   üìã Mode disponible: g√©n√©ration de forme uniquement")
                        self.texture_pipeline = None

                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Erreur g√©n√©rale texture: {e}")
                    print("   Continuation sans texture (mesh uniquement)")
                    self.texture_pipeline = None

            # Initialiser la session rembg pour la suppression d'arri√®re-plan
            try:
                import rembg
                self.rembg_session = rembg.new_session('u2net')
                print("   ‚úÖ Session rembg initialis√©e")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Session rembg non disponible: {e}")
                self.rembg_session = None

            print("‚úÖ Mod√®les charg√©s avec succ√®s!")
            return True

        except ImportError as e:
            print(f"‚ùå Erreur lors de l'importation des modules Hunyuan3D: {e}")
            print("üí° V√©rifiez que Hunyuan3D-2 est correctement install√©")
            print("üí° Ex√©cutez: python install-hunyuan3d.py")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement des mod√®les: {e}")
            print("üí° V√©rifiez que Hunyuan3D-2 est correctement install√©")
            return False

    def prepare_images(self, image_paths: List[str], remove_bg: bool = False) -> List[Image.Image]:
        """
        Pr√©pare les images pour le traitement

        Args:
            image_paths: Liste des chemins vers les images
            remove_bg: Si True, supprime l'arri√®re-plan

        Returns:
            Liste des images pr√©par√©es
        """
        print(f"üñºÔ∏è  Pr√©paration de {len(image_paths)} image(s)...")

        images = []
        for i, path in enumerate(image_paths):
            try:
                # Charger l'image
                image = Image.open(path).convert('RGB')

                # Supprimer l'arri√®re-plan si demand√©
                if remove_bg and self.rembg_session:
                    print(f"   üîÑ Suppression arri√®re-plan image {i+1}")
                    image = remove_background(
                        image, rembg_session=self.rembg_session)

                    # Traitement de l'image avec canal alpha
                    if image.mode == 'RGBA':
                        image = resize_foreground(
                            image, self.config['foreground_ratio'])
                        image_array = np.array(
                            image).astype(np.float32) / 255.0
                        # Convertir en RGB avec fond gris
                        image_array = image_array[:, :, :3] * image_array[:,
                                                                          :, 3:4] + (1 - image_array[:, :, 3:4]) * 0.5
                        image = Image.fromarray(
                            (image_array * 255.0).astype(np.uint8))
                elif remove_bg:
                    print(
                        f"   ‚ö†Ô∏è  Suppression arri√®re-plan demand√©e mais rembg non disponible")

                # Redimensionner
                image = image.resize(
                    (self.config['image_size'], self.config['image_size']))

                images.append(image)
                print(f"   ‚úÖ Image {i+1}: {image.size}")

            except Exception as e:
                print(f"   ‚ùå Erreur image {i+1}: {e}")
                continue

        return images

    def generate_3d_mesh(self, images: List[Image.Image],
                         output_dir: str = "output") -> Optional[trimesh.Trimesh]:
        """
        G√©n√®re un mesh 3D √† partir des images avec loading bar

        Args:
            images: Liste des images pr√©par√©es
            output_dir: R√©pertoire de sortie

        Returns:
            Mesh 3D g√©n√©r√© ou None en cas d'erreur
        """
        print("üèóÔ∏è  G√©n√©ration du mesh 3D...")

        if not self.shape_pipeline:
            print("‚ùå Mod√®le de forme non charg√©")
            return None

        try:
            # Pr√©parer le g√©n√©rateur
            generator = torch.Generator(
                device=self.device).manual_seed(self.config['seed'])

            # G√©n√©rer selon le nombre d'images avec loading bar
            with tqdm(total=self.config['num_inference_steps'], desc="üîÑ G√©n√©ration mesh",
                      unit="step", colour="green") as pbar:

                if len(images) > 1:
                    # Mode multi-view
                    print(f"   üîÑ Mode multi-view avec {len(images)} images")

                    # Simuler le callback de progression
                    def callback(step, timestep, latents):
                        pbar.update(1)
                        pbar.set_postfix({"timestep": f"{timestep:.1f}"})

                    mesh = self.shape_pipeline(
                        image=images,
                        guidance_scale=self.config['guidance_scale'],
                        num_inference_steps=self.config['num_inference_steps'],
                        octree_resolution=self.config['octree_resolution'],
                        num_chunks=self.config['num_chunks'],
                        generator=generator,
                        callback=callback,
                        callback_steps=1,
                        output_type='trimesh'
                    )[0]
                else:
                    # Mode single view
                    print("   üîÑ Mode single view")

                    def callback(step, timestep, latents):
                        pbar.update(1)
                        pbar.set_postfix({"timestep": f"{timestep:.1f}"})

                    mesh = self.shape_pipeline(
                        image=images[0],
                        guidance_scale=self.config['guidance_scale'],
                        num_inference_steps=self.config['num_inference_steps'],
                        octree_resolution=self.config['octree_resolution'],
                        num_chunks=self.config['num_chunks'],
                        generator=generator,
                        callback=callback,
                        callback_steps=1,
                        output_type='trimesh'
                    )[0]

            # Statistiques du mesh
            print(
                f"   ‚úÖ Mesh g√©n√©r√©: {len(mesh.vertices)} vertices, {len(mesh.faces)} faces")

            # Sauvegarder le mesh temporaire
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)

            temp_mesh_path = output_path / "temp_mesh.obj"
            mesh.export(str(temp_mesh_path))

            return mesh

        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration mesh: {e}")
            return None

    def apply_texture(self, mesh: trimesh.Trimesh,
                      reference_image: Image.Image) -> trimesh.Trimesh:
        """
        Applique une texture au mesh avec timer

        Args:
            mesh: Mesh 3D de base
            reference_image: Image de r√©f√©rence pour la texture

        Returns:
            Mesh textur√©
        """
        print("üé® Application de la texture...")

        if not self.texture_pipeline:
            print("‚ö†Ô∏è  Mod√®le de texture non charg√©, conservation du mesh sans texture")
            return mesh

        try:
            # Pr√©parer les param√®tres de texture
            texture_steps = self.config.get('texture_steps', 40)
            guidance_scale = self.config.get('texture_guidance_scale', 2.0)

            print(
                f"   üîÑ Application de texture ({texture_steps} steps, guidance={guidance_scale})...")
            print("   ‚è±Ô∏è  D√©marrage du timer...")

            # D√©marrer le timer
            start_time = time.time()

            # Appeler le pipeline de texture sans callback
            textured_mesh = self.texture_pipeline(
                mesh,
                image=reference_image,
                guidance_scale=guidance_scale,
                num_inference_steps=texture_steps
            )

            # Calculer le temps √©coul√©
            elapsed_time = time.time() - start_time
            print(
                f"   ‚è±Ô∏è  Texture appliqu√©e en {elapsed_time:.1f}s ({elapsed_time/60:.1f}min)")
            print("   ‚úÖ Texture appliqu√©e avec succ√®s")
            return textured_mesh

        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur application texture: {e}")
            print("   Retour au mesh sans texture")
            return mesh

    def apply_vertex_colors(self, mesh: trimesh.Trimesh, reference_image: Image.Image) -> trimesh.Trimesh:
        """
        Applique des couleurs de vertices rapides en √©chantillonnant les vraies couleurs de l'image

        Args:
            mesh: Mesh 3D de base
            reference_image: Image de r√©f√©rence pour les couleurs

        Returns:
            Mesh avec couleurs de vertices (rapide, sans texture)
        """
        print("üé® Application de couleurs de vertices (mode rapide)...")

        try:
            start_time = time.time()

            # Convertir l'image en array numpy
            if reference_image.mode != 'RGB':
                reference_image = reference_image.convert('RGB')

            img_array = np.array(reference_image).astype(np.float32) / 255.0
            img_height, img_width = img_array.shape[:2]

            # Calculer les normales des vertices si pas disponibles
            if not hasattr(mesh, 'vertex_normals') or mesh.vertex_normals is None:
                mesh.compute_vertex_normals()

            # Projeter les vertices sur l'image 2D (vue frontale)
            vertices = mesh.vertices

            # Normaliser les coordonn√©es X,Y des vertices vers l'espace image [0,1]
            # On utilise X,Y pour projeter sur l'image (Z = profondeur)
            x_coords = vertices[:, 0]
            y_coords = vertices[:, 1]

            # Normaliser vers [0,1]
            x_min, x_max = x_coords.min(), x_coords.max()
            y_min, y_max = y_coords.min(), y_coords.max()

            # √âviter division par z√©ro
            x_range = x_max - x_min if x_max != x_min else 1.0
            y_range = y_max - y_min if y_max != y_min else 1.0

            u_coords = (x_coords - x_min) / x_range
            v_coords = (y_coords - y_min) / y_range

            # Convertir vers coordonn√©es de pixels
            pixel_x = np.clip(u_coords * (img_width - 1),
                              0, img_width - 1).astype(int)
            pixel_y = np.clip(v_coords * (img_height - 1),
                              0, img_height - 1).astype(int)

            # √âchantillonner les couleurs directement de l'image
            sampled_colors = img_array[pixel_y, pixel_x]

            # Ajouter un tr√®s l√©ger effet de relief bas√© sur les normales (10% max)
            if hasattr(mesh, 'vertex_normals') and mesh.vertex_normals is not None:
                # Calculer un facteur de relief bas√© sur la normale Z (face avant)
                relief_factor = np.abs(
                    mesh.vertex_normals[:, 2])  # 0=profil, 1=face
                # Pour broadcasting
                relief_factor = relief_factor.reshape(-1, 1)

                # Ajuster l√©g√®rement la luminosit√© selon le relief (¬±10%)
                brightness_adjustment = 1.0 + (relief_factor - 0.5) * 0.2
                final_colors = sampled_colors * brightness_adjustment
            else:
                final_colors = sampled_colors

            # S'assurer que les couleurs sont dans la plage [0,1]
            final_colors = np.clip(final_colors, 0.0, 1.0)

            # Appliquer les couleurs au mesh (format 0-255)
            mesh.visual.vertex_colors = (final_colors * 255).astype(np.uint8)

            elapsed_time = time.time() - start_time
            print(
                f"   ‚è±Ô∏è  Couleurs de vertices appliqu√©es en {elapsed_time:.1f}s")
            print(
                f"   ‚úÖ {len(mesh.vertices)} vertices color√©s avec vraies couleurs de l'image")
            print(
                f"   üéØ Projection: {img_width}x{img_height} ‚Üí {len(mesh.vertices)} vertices")

            return mesh

        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur application couleurs vertices: {e}")
            print("   Retour au mesh sans couleurs")
            return mesh

    def render_video_with_utils(self, mesh: trimesh.Trimesh, output_dir: str = "output") -> Optional[str]:
        """
        G√©n√®re une vid√©o en rendant le mesh Hunyuan3D fourni

        Args:
            mesh: Mesh 3D Hunyuan3D √† rendre
            output_dir: R√©pertoire de sortie

        Returns:
            Chemin vers la vid√©o g√©n√©r√©e ou None en cas d'erreur
        """
        print("üé¨ Rendu vid√©o du mesh Hunyuan3D...")

        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        try:
            # Param√®tres de rendu
            n_views = self.config['n_views']
            elevation_deg = self.config['elevation_deg']
            height = self.config['height']
            width = self.config['width']
            fps = self.config['fps']
            debug_mode = self.config.get('debug_mode', False)

            # Pr√©parer le mesh avec l'orientation standard
            oriented_mesh = mesh.copy()
            oriented_mesh = to_gradio_3d_orientation(oriented_mesh)

            # Normaliser seulement si pas en mode debug (pour √©conomiser du temps)
            if not debug_mode:
                oriented_mesh = normalize_mesh(oriented_mesh)
            else:
                print("   ‚ö° Mode DEBUG - normalisation d√©sactiv√©e pour vitesse")

            render_images = []

            if debug_mode:
                print(
                    f"   üìπ Rendu DEBUG ultra-rapide: {n_views} vues minimalistes...")
            else:
                print(f"   üìπ Rendu de {n_views} vues du mesh Hunyuan3D...")

            from tqdm import tqdm
            desc = "‚ö° DEBUG ultra-rapide" if debug_mode else "üé¨ Rendu mesh Hunyuan3D"
            with tqdm(total=n_views, desc=desc, unit="vue", colour="cyan") as pbar:
                for i in range(n_views):
                    # Calculer l'azimuth pour cette vue
                    azimuth_deg = 360.0 * i / n_views

                    # Rendre la vue du mesh Hunyuan3D
                    render_image = render_mesh_view(
                        oriented_mesh,
                        azimuth_deg,
                        elevation_deg,
                        width,
                        height,
                        use_vertex_colors=True
                    )

                    render_images.append(render_image)
                    pbar.update(1)
                    pbar.set_postfix({"azimuth": f"{azimuth_deg:.1f}¬∞"})

            # Sauvegarder les images individuelles
            for ri, render_image in enumerate(render_images):
                render_image.save(output_dir / f"render_{ri:03d}.png")

            # Cr√©er la vid√©o
            if render_images:
                video_path = output_dir / "render.mp4"
                print(f"   üé¨ Cr√©ation vid√©o du mesh Hunyuan3D: {video_path}")
                save_video(render_images, str(video_path), fps=fps)
                print(
                    f"   ‚úÖ Vid√©o cr√©√©e depuis le mesh Hunyuan3D: {len(render_images)} vues")
                return str(video_path)

        except Exception as e:
            print(f"   ‚ùå Erreur rendu mesh Hunyuan3D: {e}")
            # Fallback: essayer la g√©n√©ration manuelle
            return self.render_video_manual_fallback(mesh, output_dir)

        return None

    def render_video_manual_fallback(self, mesh: trimesh.Trimesh, output_dir: Path) -> Optional[str]:
        """
        Fallback qui g√©n√®re manuellement si pas d'assets TripoSR
        """
        print("   üîÑ G√©n√©ration manuelle en fallback...")

        try:
            # Param√®tres de rendu
            n_views = self.config['n_views']
            elevation_deg = self.config['elevation_deg']
            height = self.config['height']
            width = self.config['width']
            fps = self.config['fps']

            # Pr√©parer le mesh avec l'orientation standard
            oriented_mesh = mesh.copy()
            oriented_mesh = to_gradio_3d_orientation(oriented_mesh)
            oriented_mesh = normalize_mesh(oriented_mesh)

            render_images = []

            from tqdm import tqdm
            with tqdm(total=n_views, desc="üé¨ Rendu manuel", unit="vue", colour="cyan") as pbar:
                for i in range(n_views):
                    # Calculer l'azimuth pour cette vue
                    azimuth_deg = 360.0 * i / n_views

                    # Utiliser l'utilitaire de rendu (qui cherchera d'abord TripoSR)
                    render_image = render_mesh_view(
                        oriented_mesh,
                        azimuth_deg,
                        elevation_deg,
                        width,
                        height,
                        use_vertex_colors=True
                    )

                    render_images.append(render_image)
                    pbar.update(1)
                    pbar.set_postfix({"azimuth": f"{azimuth_deg:.1f}¬∞"})

            # Sauvegarder les images individuelles
            for ri, render_image in enumerate(render_images):
                render_image.save(output_dir / f"render_{ri:03d}.png")

            # Cr√©er la vid√©o
            if render_images:
                video_path = output_dir / "render.mp4"
                save_video(render_images, str(video_path), fps=fps)
                return str(video_path)

        except Exception as e:
            print(f"   ‚ùå Erreur g√©n√©ration manuelle: {e}")
            return None

    def render_video(self, mesh: trimesh.Trimesh, output_dir: str = "output") -> Optional[str]:
        """
        G√©n√®re une vid√©o de rotation 360¬∞ (utilise les utilitaires modulaires)
        """
        return self.render_video_with_utils(mesh, output_dir)

    def post_process_mesh(self, mesh: trimesh.Trimesh) -> trimesh.Trimesh:
        """
        Post-traite le mesh pour optimiser la qualit√© tout en pr√©servant les d√©tails

        Args:
            mesh: Mesh d'entr√©e

        Returns:
            Mesh post-trait√©
        """
        print("üîß Post-processing du mesh (pr√©servation des d√©tails)...")

        try:
            # Nettoyage basique uniquement
            mesh.remove_duplicate_faces()
            mesh.remove_degenerate_faces()
            mesh.remove_unreferenced_vertices()

            # Lissage tr√®s l√©ger UNIQUEMENT si le mesh est tr√®s irr√©gulier
            # Pour pr√©server les d√©tails des pi√®ces, on applique un lissage minimal
            vertices_count = len(mesh.vertices)
            faces_count = len(mesh.faces)

            # Seulement lisser si le ratio faces/vertices est tr√®s √©lev√© (mesh tr√®s irr√©gulier)
            if vertices_count > 0 and faces_count / vertices_count > 3.0:
                print("   üîÑ Lissage minimal appliqu√© pour mesh irr√©gulier")
                # Lissage tr√®s l√©ger avec pr√©servation des d√©tails
                # Param√®tre tr√®s faible pour pr√©server les d√©tails
                mesh = mesh.smoothed(alpha=0.1)
            else:
                print("   ‚úÖ Mesh r√©gulier - pas de lissage pour pr√©server les d√©tails")

            print(
                f"   ‚úÖ Mesh optimis√©: {len(mesh.vertices)} vertices, {len(mesh.faces)} faces")
            return mesh

        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur post-processing: {e}")
            return mesh

    def convert_to_stl(self, mesh: trimesh.Trimesh, output_path: str) -> bool:
        """
        Convertit le mesh en STL

        Args:
            mesh: Mesh √† convertir
            output_path: Chemin de sortie

        Returns:
            True si succ√®s, False sinon
        """
        print("üì¶ Conversion en STL...")

        try:
            # Post-traiter le mesh seulement si autoris√©
            debug_mode = self.config.get('debug_mode', False)
            skip_post_processing = self.config.get(
                'skip_post_processing', False)

            if debug_mode:
                print("   ‚ö° Mode DEBUG - export direct sans post-processing")
                processed_mesh = mesh
            elif skip_post_processing:
                print("   ‚ö° Mode TEST - export direct sans post-processing")
                processed_mesh = mesh
            else:
                processed_mesh = self.post_process_mesh(mesh)

            # Exporter en STL
            processed_mesh.export(output_path)

            # V√©rifier le fichier
            file_size = Path(output_path).stat().st_size / 1024 / 1024  # MB
            print(f"   ‚úÖ STL g√©n√©r√©: {file_size:.2f} MB")

            return True

        except Exception as e:
            print(f"   ‚ùå Erreur conversion STL: {e}")
            return False

    def convert_coin_to_stl(self, front_image: str, back_image: str = None,
                            output_dir: str = "output_hunyuan3d",
                            remove_background: bool = False,
                            render_video: bool = True,
                            enable_post_processing: bool = False,
                            use_vertex_colors: bool = False) -> Optional[str]:
        """
        Convertit une pi√®ce (avers/revers) en STL avec utilitaires modulaires

        Args:
            front_image: Chemin vers l'image de face
            back_image: Chemin vers l'image de dos (optionnel)
            output_dir: R√©pertoire de sortie
            remove_background: Supprimer l'arri√®re-plan
            render_video: G√©n√©rer une vid√©o de rotation
            enable_post_processing: Activer le post-processing du mesh
            use_vertex_colors: Utiliser des couleurs de vertices rapides (2-5s au lieu de 8+ min)

        Returns:
            Chemin vers le fichier STL ou None en cas d'erreur
        """
        print("ü™ô Conversion de pi√®ce avec Hunyuan3D-2mv (utilitaires modulaires)")
        print("=" * 70)

        start_time = time.time()

        # Pr√©parer les images
        image_paths = [front_image]
        if back_image:
            image_paths.append(back_image)

        images = self.prepare_images(image_paths, remove_background)
        if not images:
            print("‚ùå Aucune image pr√©par√©e")
            return None

        # G√©n√©rer le mesh 3D
        mesh = self.generate_3d_mesh(images, output_dir)
        if not mesh:
            print("‚ùå √âchec g√©n√©ration mesh")
            return None

        # Appliquer la texture ou les couleurs de vertices selon le mode
        if use_vertex_colors:
            # Mode vertex colors rapide (quelques secondes)
            colored_mesh = self.apply_vertex_colors(mesh, images[0])
            print(
                f"   üìä Mesh avec vertex colors: {len(colored_mesh.vertices)} vertices, {len(colored_mesh.faces)} faces")
        elif not self.disable_texture and self.texture_pipeline:
            # Mode texture complet (8+ minutes)
            colored_mesh = self.apply_texture(mesh, images[0])
            print(
                f"   üìä Mesh avec texture: {len(colored_mesh.vertices)} vertices, {len(colored_mesh.faces)} faces")
        else:
            # Mode sans couleur ni texture (ultra-rapide)
            colored_mesh = mesh
            print(
                f"   üìä Mesh sans couleur: {len(colored_mesh.vertices)} vertices, {len(colored_mesh.faces)} faces")

        # Post-traiter le mesh si activ√©
        skip_post_processing = self.config.get('skip_post_processing', False)
        debug_mode = self.config.get('debug_mode', False)

        if debug_mode:
            print("üîÑ Mode DEBUG - aucun post-processing (mesh brut instantan√©)")
            print(
                f"   ‚ö° √âconomie maximale: {len(colored_mesh.vertices)} vertices pr√©serv√©s")
            final_mesh = colored_mesh
        elif enable_post_processing and not skip_post_processing:
            print("üîÑ Post-processing activ√© (peut ajouter des vertices)")
            final_mesh = self.post_process_mesh(colored_mesh)
        elif skip_post_processing:
            print("üîÑ Post-processing d√©sactiv√© en mode test (pr√©serve le mesh)")
            print(f"   üí° √âconomie: pas d'ajout de vertices suppl√©mentaires")
            final_mesh = colored_mesh
        else:
            print("üîÑ Post-processing d√©sactiv√© - pr√©servation maximale des d√©tails")
            final_mesh = colored_mesh

        # Convertir en STL
        stl_path = Path(output_dir) / "coin_model.stl"
        if self.convert_to_stl(final_mesh, str(stl_path)):
            elapsed_time = time.time() - start_time

            print(f"\n‚úÖ Conversion termin√©e en {elapsed_time:.1f}s")
            print(f"üìÅ Fichier STL: {stl_path}")

            # G√©n√©rer la vid√©o si demand√© (avec utilitaires modulaires)
            if render_video:
                video_path = self.render_video(final_mesh, output_dir)
                if video_path:
                    print(
                        f"üé¨ Vid√©o g√©n√©r√©e (utilitaires modulaires): {video_path}")

            if back_image:
                print("üîÑ Mod√®le g√©n√©r√© avec avers et revers")
            else:
                print("üîÑ Mod√®le g√©n√©r√© avec vue unique")

            return str(stl_path)

        return None


def convert_coin_hunyuan3d(front_image: str, back_image: str = None,
                           output_dir: str = "output_hunyuan3d",
                           model_path: str = "tencent/Hunyuan3D-2",
                           remove_background: bool = False,
                           render_video: bool = True,
                           enable_post_processing: bool = False,
                           use_vertex_colors: bool = False) -> Optional[str]:
    """
    Fonction de convenance pour convertir une pi√®ce avec Hunyuan3D-2mv

    Args:
        front_image: Chemin vers l'image de face
        back_image: Chemin vers l'image de dos (optionnel)
        output_dir: R√©pertoire de sortie
        model_path: Chemin vers le mod√®le Hunyuan3D
        remove_background: Supprimer l'arri√®re-plan
        render_video: G√©n√©rer une vid√©o de rotation
        enable_post_processing: Activer le post-processing du mesh
        use_vertex_colors: Utiliser des couleurs de vertices rapides (2-5s au lieu de 8+ min)

    Returns:
        Chemin vers le fichier STL ou None en cas d'erreur
    """
    # Cr√©er le convertisseur
    converter = Hunyuan3DConverter(model_path)

    # V√©rifier l'environnement
    if not converter.check_environment():
        return None

    # Charger les mod√®les
    if not converter.load_models():
        return None

    # Convertir
    return converter.convert_coin_to_stl(
        front_image, back_image, output_dir, remove_background, render_video, enable_post_processing, use_vertex_colors
    )


def get_hunyuan3d_info():
    """Retourne des informations sur Hunyuan3D-2"""
    info = {
        'name': 'Hunyuan3D-2mv (compl√®tement ind√©pendant)',
        'description': 'Mod√®le de g√©n√©ration 3D multi-view avec rendu vid√©o ind√©pendant',
        'version': '2.0 (nettoy√©)',
        'features': [
            'Support multi-view (avers/revers)',
            'G√©n√©ration haute r√©solution',
            'Texture r√©aliste',
            'Rendu vid√©o ind√©pendant (sans TripoSR)',
            'Loading bars de progression',
            'Suppression arri√®re-plan',
            'Modes qualit√©: debug, low, medium, high, ultra',
            'Compl√®tement ind√©pendant de TripoSR'
        ],
        'utils': [
            'Utilitaires modulaires ind√©pendants',
            'Rendu vid√©o sans TripoSR',
            'Couleurs de vertices rapides',
            'Post-processing optimis√©',
            'Configuration par niveaux de qualit√©'
        ],
        'requirements': [
            'CUDA 11.8+ (recommand√©)',
            'GPU avec 16GB+ VRAM',
            'Python 3.8+',
            'Hunyuan3D-2 install√©',
            'tqdm pour les loading bars',
            'matplotlib pour le rendu vid√©o'
        ]
    }
    return info
